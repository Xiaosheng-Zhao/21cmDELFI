{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The active learning\n",
    "In this notebook, we incorporate the [21cmSense](https://github.com/steven-murray/21cmSense) and [21cmFAST](https://github.com/andreimesinger/21cmFAST) into the [pydelfi](https://github.com/justinalsing/pydelfi) package to perform the inference with active learning [(Alsing et al. 2019)](https://ui.adsabs.harvard.edu/abs/2019MNRAS.488.4440A).\n",
    "\n",
    "Active-learning inference focuses on the most probable region during inference and only trains the NDEs optimized in this local region, so it can effectively save the cost for simulations for inference with one observation data. However, this ''training during inference'' process should be repeated for inference with a new observation data, so it is computationally expensive to implement post-validations with many mock observations, each using active-learning inference.\n",
    "\n",
    "We set the \"n_noise\" as a free parameter which correspond to the number of realizations of noise for a given set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the directory for the cache of 21cmFAST and results from delfi\n",
    "!mkdir ./data/cache\n",
    "!mkdir ./data/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5976\r\n",
      "drwxrwxr-x 2 zxs zxs      10 Feb 17 15:25 cache\r\n",
      "drwxrwxr-x 3 zxs zxs     291 Nov  7 15:10 diagnostics\r\n",
      "-rw-rw-r-- 1 zxs zxs  144128 Nov  7 14:56 hera_para.npy\r\n",
      "-rw-rw-r-- 1 zxs zxs     160 Nov  7 14:58 hera_para_mock.npy\r\n",
      "-rw-rw-r-- 1 zxs zxs    4928 Nov  7 14:55 hera_para_validation.npy\r\n",
      "-rw-rw-r-- 1 zxs zxs 5760128 Nov  7 14:56 hera_ps.npy\r\n",
      "-rw-rw-r-- 1 zxs zxs    1408 Nov  7 14:58 hera_ps_mock.npy\r\n",
      "-rw-rw-r-- 1 zxs zxs  192128 Nov  7 14:55 hera_ps_validation.npy\r\n",
      "drwxrwxr-x 2 zxs zxs      10 Nov  7 15:10 posterior_samples\r\n",
      "drwxrwxr-x 2 zxs zxs      10 Feb 17 15:25 results\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Active_learning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Active_learning.py\n",
    "import logging, sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydelfi.priors as priors\n",
    "import pydelfi.ndes as ndes\n",
    "import pydelfi.delfi as delfi\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "\n",
    "logger = logging.getLogger('21cmFAST')\n",
    "logger.setLevel(logging.INFO)\n",
    "import py21cmfast as p21c\n",
    "from py21cmfast import plotting\n",
    "from py21cmfast import cache_tools\n",
    "from tpower import get_power\n",
    "import random\n",
    "from mpi4py import MPI\n",
    "\n",
    "restore=False\n",
    "#one set of parameters could correspond to multiple realizations of noise\n",
    "n_noise=1\n",
    "\n",
    "def simulator(theta,seed,simulator_args,batch=1,n_noise=n_noise):\n",
    "    p21c.config['direc'] = \"./data/cache\"\n",
    "    nc = 66\n",
    "    redshift = [7.668188,8.003182,8.357909,8.716638,9.108561,9.524624,9.966855,10.437500,10.939049,11.474274]\n",
    "    coeval8 = p21c.run_coeval(\n",
    "    redshift = redshift,\n",
    "    write=False,\n",
    "    user_params = {\"HII_DIM\": 66, \"BOX_LEN\": 100},\n",
    "    cosmo_params = p21c.CosmoParams(SIGMA_8=0.815,hlittle=0.678,OMm=0.308,OMb=0.048425,POWER_INDEX=0.968),\n",
    "    astro_params = p21c.AstroParams({\"HII_EFF_FACTOR\":pow(10,theta[1]),\"ION_Tvir_MIN\":theta[0]}),\n",
    "    random_seed=seed)\n",
    "    ps = np.concatenate((get_power(coeval8[0],nc,n_noise,redshift[0]),get_power(coeval8[1],nc,n_noise,redshift[1]),get_power(coeval8[2],nc,n_noise,redshift[2]),get_power(coeval8[3],nc,n_noise,redshift[3]),get_power(coeval8[4],nc,n_noise,redshift[4]),get_power(coeval8[5],nc,n_noise,redshift[5]),get_power(coeval8[6],nc,n_noise,redshift[6]),get_power(coeval8[7],nc,n_noise,redshift[7]),get_power(coeval8[8],nc,n_noise,redshift[8]),get_power(coeval8[9],nc,n_noise,redshift[9])),axis=1)\n",
    "    return ps\n",
    "\n",
    "# Simulator arguments\n",
    "simulator_args = None\n",
    "def compressor(d, compressor_args):\n",
    "    return d\n",
    "compressor_args = None\n",
    "\n",
    "# Define the priors parameters\n",
    "lower = np.array([4,1])\n",
    "upper = np.array([6,2.398])\n",
    "prior = priors.Uniform(lower, upper)\n",
    "theta_fiducial = np.array([5.47712125,2.30103])\n",
    "\n",
    "seed = 4101110\n",
    "nout = 80\n",
    "\n",
    "data=np.load('/scratch/zxs/delfi_fast/data/21cmdelfi_mock/back_1003/bright_hera.npy')\n",
    "compressed_data = compressor(data, compressor_args)\n",
    "\n",
    "# Create an ensemble of NDEs\n",
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=nout, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=0),\n",
    "            ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=nout, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=1),\n",
    "            ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=nout, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=2),\n",
    "            ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=nout, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=3)]\n",
    "\n",
    "# Initiate the MPI setting\n",
    "world_comm=MPI.COMM_WORLD\n",
    "print (world_comm.Get_rank(),flush=True)\n",
    "# Create the DELFI object\n",
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, Finv=None, theta_fiducial=theta_fiducial,\n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names =['\\mathrm{log_{10}\\,T_{vir}}', '\\mathrm{log_{10}\\,\\zeta}'],\n",
    "                       results_dir = \"./data/results\",\n",
    "                       restore = restore,\n",
    "                       n_procs = 10,\n",
    "                       comm=world_comm,\n",
    "                       red_op=MPI.SUM,\n",
    "                       n_noise=n_noise,\n",
    "                       rank=world_comm.Get_rank(),\n",
    "                       input_normalization=None)\n",
    "\n",
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 500\n",
    "n_batch = 500\n",
    "n_populations = 60\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=20, batch_size = 100,plot = False,save_intermediate_posteriors=True)\n",
    "x0 = DelfiEnsemble.posterior_samples[np.random.choice(np.arange(len(DelfiEnsemble.posterior_samples)), p=DelfiEnsemble.posterior_weights.astype(np.float32)/sum(DelfiEnsemble.posterior_weights), replace=False, size=DelfiEnsemble.nwalkers),:]\n",
    "posterior_samples = DelfiEnsemble.emcee_sample(x0=x0,main_chain=2000)\n",
    "\n",
    "with open('data/posterior_samples/po_mock_active.pkl', 'wb') as f:\n",
    "    pickle.dump(posterior_samples,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpiexec:  unexpected error - no non-PBS mpiexec in PATH\r\n"
     ]
    }
   ],
   "source": [
    "#mpi parallel for efficiently generate the simulation data\n",
    "!mpiexec -n 10 python active_mpi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
